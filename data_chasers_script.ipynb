{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset loading\n",
    "\n",
    "# Reading csv files\n",
    "# gddAprOct = pd.read_csv(\"dataset/10_4231_R72F7KK2/Agro-Climatic Data by County/gddAprOct.csv\")\n",
    "# gridInfo = pd.read_csv(\"dataset/10_4231_R72F7KK2/Agro-Climatic Data by County/gridInfo.csv\")\n",
    "# yielddata = pd.read_csv(\"dataset/10_4231_R72F7KK2/Agro-Climatic Data by County/yielddata.csv\")\n",
    "crime_data = pd.read_csv(\"../../../../Downloads/Crimes_-_2001_to_present.csv\")\n",
    "\n",
    "# Reading txt files\n",
    "# txt_data = ''\n",
    "# with open('dataset/CAF_Sensor_Dataset_2/CAF_CropCodes.txt','r') as file:\n",
    "#     txt_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Earlier analysis\n",
    "\n",
    "# Dataset-1\n",
    "gddAprOct.head()\n",
    "gddAprOct['year'].head()\n",
    "gddAprOct['year'].min()\n",
    "gddAprOct['year'].max()\n",
    "gddAprOct.shape\n",
    "gddAprOct['gddm60'].isna().sum()\n",
    "gddAprOct.max().max()\n",
    "len(gddAprOct.loc[gddAprOct['gddm5'] == 0.0])\n",
    "\n",
    "# Dataset-2\n",
    "gridInfo.head()\n",
    "gridInfo.shape\n",
    "\n",
    "# Dataset-3\n",
    "yielddata.head()\n",
    "yielddata['corn'].isna().sum()\n",
    "yielddata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygooglechart import PieChart3D\n",
    "\n",
    "def python_pie3D(data, labels) :\n",
    "  # initialize chart object, 250 x 250 pixels\n",
    "  chart = PieChart3D(250, 250)\n",
    "\n",
    "  # pass your data to the chart object\n",
    "  chart.add_data(data)\n",
    "\n",
    "  # make labels for the slices\n",
    "  chart.set_pie_labels(labels)\n",
    "\n",
    "  # render the image\n",
    "  chart.download('revenue_east_europe.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "# Analysis harness\n",
    "analysis_df = crime_data\n",
    "\n",
    "# To show different metrics\n",
    "# analysis_df.info()\n",
    "# analysis_df['Arrest'].describe()\n",
    "\n",
    "# import numpy as np\n",
    "# from matplotlib import cm\n",
    "# color = cm.inferno_r(np.linspace(.4,.8, 30))\n",
    "\n",
    "# analysis_df.groupby(['Primary Type', 'Arrest']).size().unstack().plot(kind='barh', stacked=True, figsize=(10,10))\n",
    "# df2 = analysis_df.groupby(['Primary Type', 'Arrest'])['Primary Type'].count().unstack('Arrest').fillna(0)\n",
    "# print (df2.head())\n",
    "# df2[[False,True]].plot(kind='bar', stacked=True)\n",
    "\n",
    "# analysis_df['Primary Type'].value_counts().plot(kind='barh', figsize=(10,10), color=color)\n",
    "# analysis_df.isnull().sum().plot(kind='barh', figsize=(10,10), color=color)\n",
    "# analysis_df[analysis_df['Arrest']==False]['Primary Type'].value_counts().plot(kind='pie', figsize=(10,10))\n",
    "# df = analysis_df[analysis_df['Arrest']==False]['Primary Type'].value_counts()\n",
    "# python_pie3D(df.data, df.index)\n",
    "\n",
    "# To get null values\n",
    "# analysis_df.isnull().sum()\n",
    "\n",
    "# Finding co-relation\n",
    "# correlation_matrix = analysis_df.corr().round(2)\n",
    "# sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts txt to csv files\n",
    "import csv \n",
    "\n",
    "def txt_to_csv(txt_file):\n",
    "    csv_file = txt_file.split('/')[-1].split('.')[0] + '.csv'\n",
    "    csv_file = '/'.join(txt_file.split('/')[:-1]) + '/' + csv_file\n",
    "    \n",
    "    inp_data = list()\n",
    "    with open(txt_file, 'r') as in_file:\n",
    "        stripped = (line.strip() for line in in_file)\n",
    "        inp_data = [line.split(\"\\t\") for line in stripped if line]\n",
    "    \n",
    "    # creating dataframe\n",
    "    df = pd.DataFrame(inp_data[1:-2], columns=inp_data[0])\n",
    "    print(df.head())\n",
    "    df.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "txt_to_csv('dataset/CAF_Sensor_Dataset_2/CAF_CropID.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class API_client:\n",
    "    def __init__(self, url, username, password):\n",
    "        self._url = url\n",
    "        self._auth = (username, password)\n",
    "        \n",
    "    def set_url(self, url):\n",
    "        '''\n",
    "        to reset url\n",
    "        '''\n",
    "        self._url = url\n",
    "        \n",
    "    def get_response(self):\n",
    "        '''\n",
    "        get response from url\n",
    "        '''\n",
    "        resp = requests.get(self._url, auth=self._auth)\n",
    "        \n",
    "        if resp.status_code != 200:\n",
    "            # This means something went wrong.\n",
    "            raise ApiError('GET rest API issue: {}'.format(resp.status_code))\n",
    "            \n",
    "        return resp.json()\n",
    "    \n",
    "    def put_response(self, data):\n",
    "        '''\n",
    "        put response\n",
    "        '''\n",
    "        resp = requests.post(self._url, auth=self._auth, json=data)\n",
    "        \n",
    "        if resp.status_code != 201:\n",
    "            raise ApiError('POST rest API issue: {}'.format(resp.status_code))\n",
    "            \n",
    "        return 'POST successful'\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'This is a REST API functions wrapper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# analysis_df = analysis_df.to_json(orient='index')\n",
    "host_name = 'http://localhost:8091'\n",
    "rest_client = API_client(couchbase_url, 'administrator', 'nainyjain')\n",
    "\n",
    "# Exploration\n",
    "url_1 = '/pools/default/buckets'\n",
    "\n",
    "rest_client.set_url(host_name+url_1)\n",
    "print (rest_client.get_response())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.cluster import PasswordAuthenticator\n",
    "cluster = Cluster('couchbase://localhost')\n",
    "authenticator = PasswordAuthenticator('administrator', 'nainyjain')\n",
    "cluster.authenticate(authenticator)\n",
    "cb = cluster.open_bucket('sample_data')\n",
    "\n",
    "for index, doc in enumerate(analysis_df[:100000].T.to_dict().values()):\n",
    "    doc_id = 'k' + str(index)\n",
    "    cb.upsert(doc_id, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
